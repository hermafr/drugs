{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corpus_reader import read_dataset\n",
    "#from n_gram_naive_bayes import trained_naive_bayes, extract_features_and_classify\n",
    "\n",
    "from word_extraction import remove_puntuations\n",
    "from numpy.random import choice\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 training documents\n",
      "215 test documents\n"
     ]
    }
   ],
   "source": [
    "data = read_dataset()\n",
    "n_docs = len(data)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_amount = 0.7\n",
    "train_ids = choice(n_docs, int(train_amount * n_docs), replace=False)\n",
    "test_ids = [i for i in range(n_docs) if i not in train_ids]\n",
    "\n",
    "training = [data[i] for i in train_ids]\n",
    "test = [data[i] for i in test_ids]\n",
    "\n",
    "print(\"%i training documents\" % len(training))\n",
    "print(\"%i test documents\" % len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#given a list of document, iterate over the sentences and output a dictionnary counting words occuring\n",
    "#between drugs and also the number of pairs\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.nbPairs = 0\n",
    "        self.count_words = {}\n",
    "        \n",
    "        self.nb_feature_words = 20\n",
    "        self.feature_words = []\n",
    "        self.feature_index = {}\n",
    "        \n",
    "        self.clf = None\n",
    "        \n",
    "        \n",
    "        #given a class, gives the corresponding value\n",
    "        self.class_index = {\n",
    "            'null': 0,\n",
    "            'advise' : 1,\n",
    "            'effect':2,\n",
    "            'int':3,\n",
    "            'mechanism':4\n",
    "        }\n",
    "        \n",
    "        #given a class value, gives the corresponding label\n",
    "        self.class_mapping = {v: k for k, v in self.class_index.items()}\n",
    "\n",
    "\n",
    "    def get_interaction_text_list(self, pair):\n",
    "        text = re.split(\"\\W+\", pair.textBetween)\n",
    "        return \" \".join([w for w in text if w != \"\"])\n",
    "    \n",
    "    #count specific words in doc list\n",
    "    def count_words_doc(self, doc_list, nb=-1, verbose = False):\n",
    "        nb = len(doc_list) if nb == -1 else nb\n",
    "        for doc in doc_list[0:nb]:\n",
    "            for sentence in doc.sentences:\n",
    "                if len(sentence.entities) >= 2:\n",
    "                    self.nbPairs += len(sentence.pairs)\n",
    "                    all_interaction_text = [self.get_interaction_text_list(p) for p in sentence.pairs]\n",
    "                    if verbose:\n",
    "                        print(sentence.text)\n",
    "                        print(all_interaction_text)\n",
    "                        print([e.text for e in sentence.entities])\n",
    "                        print([str(p) for p in sentence.pairs])\n",
    "\n",
    "                        print(\"\\n-------\\n\")\n",
    "                    \n",
    "                    for interaction_text in all_interaction_text:\n",
    "                        for w in interaction_text:\n",
    "                            self.count_words[w] = self.count_words.get(w,0) + 1\n",
    "    \n",
    "    def create_feature_word_list(self, nb_feature_words = 20):\n",
    "        srt = sorted([(self.count_words[w], w) for w in self.count_words], reverse = True)\n",
    "        \n",
    "        self.nb_feature_words = nb_feature_words\n",
    "        self.feature_words = [w for (n,w) in srt[:nb_feature_words]]\n",
    "        \n",
    "        self.feature_index = {}\n",
    "\n",
    "        for (i,feat) in enumerate(self.feature_words):\n",
    "            self.feature_index[feat] = i\n",
    "    \n",
    "    def get_feature_from_text(self, wordList):\n",
    "        output = np.zeros(self.nb_feature_words)\n",
    "        for w in wordList:\n",
    "            if w in self.feature_index:\n",
    "                output[self.feature_index[w]] = 1\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_features_from_pair(self, pair):\n",
    "        text = re.split(\"\\W+\", pair.textBetween)\n",
    "        text = \" \".join([w for w in text if w != \"\"])\n",
    "        \n",
    "        return self.get_feature_from_text(text)\n",
    "    \n",
    "    def create_feature_matrix_and_labels(self,doc_list, nb = -1, verbose = False):\n",
    "        currPair = 0\n",
    "        \n",
    "        ncol = self.nb_feature_words\n",
    "        nrow = self.nbPairs\n",
    "\n",
    "        matrixFeature = np.zeros(shape=(nrow, ncol))\n",
    "        \n",
    "        labels = [0]*self.nbPairs\n",
    "        \n",
    "        nb = len(doc_list) if nb == -1 else nb\n",
    "        for doc in doc_list[0:nb]:\n",
    "            for sentence in doc.sentences:\n",
    "                if len(sentence.entities) >= 2:\n",
    "                    \n",
    "                    for p in sentence.pairs:\n",
    "                        matrixFeature[currPair] = self.get_features_from_pair(p)\n",
    "                        labels[currPair] = self.class_index[p.getLabel()]\n",
    "                        currPair += 1\n",
    "                    \n",
    "                    if verbose == True:\n",
    "                        print(sentence.text)\n",
    "                        print([e.text for e in sentence.entities])\n",
    "                        #print([get_necessary_info(p, sentence.text) for p in sentence.pairs])\n",
    "                    \n",
    "                        \n",
    "                        #print(all_interaction_text)\n",
    "                        print(\"\\n-------\\n\")\n",
    "        \n",
    "        if verbose == \"minim\":\n",
    "            print(\"Done.\")\n",
    "        \n",
    "        return [matrixFeature, labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psvm = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Total number of pairs: 20869\n"
     ]
    }
   ],
   "source": [
    "psvm.count_words_doc(training)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Total number of pairs: \" + str(psvm.nbPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psvm.create_feature_word_list(nb_feature_words = 100)\n",
    "#print(\"Showing most \"+ str(nb_feature_words) + \" frequent words.\")\n",
    "\n",
    "#for e in srt[:nb_feature_words]:\n",
    "#    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "temp = psvm.create_feature_matrix_and_labels(training)\n",
    "\n",
    "trainingFeature = temp[0]\n",
    "labels = np.array(temp[1])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_balancing(labels):\n",
    "    c = {}\n",
    "    for l in labels:\n",
    "        c[l] = c.get(l,0) + 1\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC (but not NuSVC) implement a keyword class_weight in the fit method.\n",
    "#Itâ€™s a dictionary of the form {class_label : value}, where value is a floating point number > 0\n",
    "#as it is unbalanced, balance the classes\n",
    "c = count_balancing(labels)\n",
    "weight = {i: psvm.nbPairs/float(c[i]) for i in c.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 17937, 1: 599, 2: 1205, 3: 138, 4: 990}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1634610023972793,\n",
       " 1: 34.83973288814691,\n",
       " 2: 17.318672199170123,\n",
       " 3: 151.2246376811594,\n",
       " 4: 21.07979797979798}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#define the SVM\n",
    "psvm.clf = svm.LinearSVC()\n",
    "#psvm.clf = svm.LinearSVC(class_weight=weight)\n",
    "#psvm.clf = svm.SVC(probability=True, class_weight=weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 43.2039999962s\n"
     ]
    }
   ],
   "source": [
    "#train it\n",
    "start = time()\n",
    "psvm.clf.fit(trainingFeature,labels)\n",
    "print (\"Done in \" + str(time() - start) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#self.class_index = {\n",
    "#            'null': 0,\n",
    "#            'advise' : 1,\n",
    "#            'effect':2,\n",
    "#            'int':3,\n",
    "#            'mechanism':4\n",
    "#        }\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "precision_count = {\n",
    "    'null': {},\n",
    "    'advise' : {},\n",
    "    'effect': {},\n",
    "    'int': {},\n",
    "    'mechanism': {}\n",
    "}\n",
    "\n",
    "for k in precision_count:\n",
    "    precision_count[k] = {\n",
    "        \"true_positive\" : 0,\n",
    "        \"false_positive\" : 0,\n",
    "        \"false_negative\" : 0,\n",
    "\n",
    "        \"correct\" : 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TUNE C !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tdoc in test:\n",
    "    for sentence in tdoc.sentences:\n",
    "        if len(sentence.entities) >= 2:\n",
    "            for p in sentence.pairs:\n",
    "                s = p.textBetween\n",
    "                s = s.lower().split(' ')\n",
    "                f = psvm.get_feature_from_text(s).reshape(1,-1)\n",
    "                \n",
    "                pred = psvm.class_mapping[psvm.clf.predict(f)[0]]\n",
    "                true = p.getLabel()\n",
    "                \n",
    "                if pred == true:\n",
    "                    precision_count[pred][\"true_positive\"] += 1\n",
    "                elif pred != true:\n",
    "                    precision_count[pred][\"false_positive\"] += 1\n",
    "                    precision_count[true][\"false_negative\"] += 1\n",
    "                \n",
    "                total += 1\n",
    "                \n",
    "                if pred == true:\n",
    "                    correct += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_score(count, label):\n",
    "    print(\"> %i true positives\" % count[label][\"true_positive\"])\n",
    "    print(\"> %i false positives\" % count[label][\"false_positive\"])\n",
    "    print(\"> %i false negatives\" % count[label][\"false_negative\"])\n",
    "    precision = float(count[label][\"true_positive\"]) / (count[label][\"true_positive\"] + count[label][\"false_positive\"]+1)\n",
    "    recall = float(count[label][\"true_positive\"]) / (count[label][\"true_positive\"] + count[label][\"false_negative\"]+1)\n",
    "\n",
    "    print(\"> recall: %f\" % recall)\n",
    "    print(\"> precision: %f\" % precision)\n",
    "    print(\"-\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class int:\n",
      "> 0 true positives\n",
      "> 0 false positives\n",
      "> 50 false negatives\n",
      "> recall: 0.000000\n",
      "> precision: 0.000000\n",
      "-----\n",
      "Precision for class advise:\n",
      "> 0 true positives\n",
      "> 0 false positives\n",
      "> 227 false negatives\n",
      "> recall: 0.000000\n",
      "> precision: 0.000000\n",
      "-----\n",
      "Precision for class null:\n",
      "> 5834 true positives\n",
      "> 1089 false positives\n",
      "> 0 false negatives\n",
      "> recall: 0.999829\n",
      "> precision: 0.842577\n",
      "-----\n",
      "Precision for class effect:\n",
      "> 0 true positives\n",
      "> 0 false positives\n",
      "> 483 false negatives\n",
      "> recall: 0.000000\n",
      "> precision: 0.000000\n",
      "-----\n",
      "Precision for class mechanism:\n",
      "> 0 true positives\n",
      "> 0 false positives\n",
      "> 329 false negatives\n",
      "> recall: 0.000000\n",
      "> precision: 0.000000\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for k in precision_count:\n",
    "    print(\"Precision for class \"+k+\":\")\n",
    "    print_score(precision_count, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 5834\n",
      "total: 6923\n",
      "accuracy: 84.27%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = round(100*100*float(correct)/total)/100\n",
    "print(\"correct: \"+str(correct))\n",
    "print(\"total: \"+str(total))\n",
    "print(\"accuracy: \"+str(accuracy)+ \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
