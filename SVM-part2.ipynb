{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corpus_reader import read_dataset\n",
    "#from n_gram_naive_bayes import trained_naive_bayes, extract_features_and_classify\n",
    "\n",
    "from word_extraction import remove_puntuations\n",
    "from numpy.random import choice\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 training documents\n",
      "215 test documents\n"
     ]
    }
   ],
   "source": [
    "data = read_dataset()\n",
    "n_docs = len(data)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_amount = 0.7\n",
    "train_ids = choice(n_docs, int(train_amount * n_docs), replace=False)\n",
    "test_ids = [i for i in range(n_docs) if i not in train_ids]\n",
    "\n",
    "training = [data[i] for i in train_ids]\n",
    "test = [data[i] for i in test_ids]\n",
    "\n",
    "print(\"%i training documents\" % len(training))\n",
    "print(\"%i test documents\" % len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#given a list of document, iterate over the sentences and output a dictionnary counting words occuring\n",
    "#between drugs and also the number of pairs\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.nbPairs = 0\n",
    "        self.count_words = {}\n",
    "        \n",
    "        self.nb_feature_words = 20\n",
    "        self.feature_words = []\n",
    "        self.feature_index = {}\n",
    "        \n",
    "        self.clf = None\n",
    "        \n",
    "        \n",
    "        #given a class, gives the corresponding value\n",
    "        self.class_index = {\n",
    "            'no_interaction': 0,\n",
    "            'advise' : 1,\n",
    "            'effect':2,\n",
    "            'int':3,\n",
    "            'mechanism':4\n",
    "        }\n",
    "        \n",
    "        #given a class value, gives the corresponding label\n",
    "        self.class_mapping = {v: k for k, v in self.class_index.items()}\n",
    "\n",
    "\n",
    "    def get_interaction_text_list(self, pair):\n",
    "        text = re.split(\"\\W+\", pair.textBetween)\n",
    "        return \" \".join([w for w in text if w != \"\"])\n",
    "    \n",
    "    #count specific words in doc list\n",
    "    def count_words_doc(self, doc_list, nb=-1, verbose = False):\n",
    "        nb = len(doc_list) if nb == -1 else nb\n",
    "        for doc in doc_list[0:nb]:\n",
    "            for sentence in doc.sentences:\n",
    "                if len(sentence.entities) >= 2:\n",
    "                    self.nbPairs += len(sentence.pairs)\n",
    "                    all_interaction_text = [self.get_interaction_text_list(p) for p in sentence.pairs]\n",
    "                    if verbose:\n",
    "                        print(sentence.text)\n",
    "                        print(all_interaction_text)\n",
    "                        print([e.text for e in sentence.entities])\n",
    "                        print([str(p) for p in sentence.pairs])\n",
    "\n",
    "                        print(\"\\n-------\\n\")\n",
    "                    \n",
    "                    for interaction_text in all_interaction_text:\n",
    "                        for w in interaction_text:\n",
    "                            self.count_words[w] = self.count_words.get(w,0) + 1\n",
    "    \n",
    "    def create_feature_word_list(self, nb_feature_words = 20):\n",
    "        srt = sorted([(self.count_words[w], w) for w in self.count_words], reverse = True)\n",
    "        \n",
    "        self.nb_feature_words = nb_feature_words\n",
    "        self.feature_words = [w for (n,w) in srt[:nb_feature_words]]\n",
    "        \n",
    "        self.feature_index = {}\n",
    "\n",
    "        for (i,feat) in enumerate(self.feature_words):\n",
    "            self.feature_index[feat] = i\n",
    "    \n",
    "    def get_feature_from_text(self, wordList):\n",
    "        output = np.zeros(self.nb_feature_words)\n",
    "        for w in wordList:\n",
    "            if w in self.feature_index:\n",
    "                output[self.feature_index[w]] = 1\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_features_from_pair(self, pair):\n",
    "        text = re.split(\"\\W+\", pair.textBetween)\n",
    "        text = \" \".join([w for w in text if w != \"\"])\n",
    "        \n",
    "        return self.get_feature_from_text(text)\n",
    "    \n",
    "    def create_feature_matrix_and_labels(self,doc_list, nb = -1, verbose = False):\n",
    "        currPair = 0\n",
    "        \n",
    "        ncol = self.nb_feature_words\n",
    "        nrow = self.nbPairs\n",
    "\n",
    "        matrixFeature = np.zeros(shape=(nrow, ncol))\n",
    "        \n",
    "        labels = [0]*self.nbPairs\n",
    "        \n",
    "        nb = len(doc_list) if nb == -1 else nb\n",
    "        for doc in doc_list[0:nb]:\n",
    "            for sentence in doc.sentences:\n",
    "                if len(sentence.entities) >= 2:\n",
    "                    \n",
    "                    for p in sentence.pairs:\n",
    "                        matrixFeature[currPair] = self.get_features_from_pair(p)\n",
    "                        labels[currPair] = self.class_index[p.getLabel()]\n",
    "                        currPair += 1\n",
    "                    \n",
    "                    if verbose == True:\n",
    "                        print(sentence.text)\n",
    "                        print([e.text for e in sentence.entities])\n",
    "                        #print([get_necessary_info(p, sentence.text) for p in sentence.pairs])\n",
    "                    \n",
    "                        \n",
    "                        #print(all_interaction_text)\n",
    "                        print(\"\\n-------\\n\")\n",
    "        \n",
    "        if verbose == \"minim\":\n",
    "            print(\"Done.\")\n",
    "        \n",
    "        return [matrixFeature, labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psvm = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Total number of pairs: 20916\n"
     ]
    }
   ],
   "source": [
    "psvm.count_words_doc(training)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Total number of pairs: \" + str(psvm.nbPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psvm.create_feature_word_list(nb_feature_words = 20)\n",
    "#print(\"Showing most \"+ str(nb_feature_words) + \" frequent words.\")\n",
    "\n",
    "#for e in srt[:nb_feature_words]:\n",
    "#    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "temp = psvm.create_feature_matrix_and_labels(training)\n",
    "\n",
    "trainingFeature = temp[0]\n",
    "labels = np.array(temp[1])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_balancing(labels):\n",
    "    c = {}\n",
    "    for l in labels:\n",
    "        c[l] = c.get(l,0) + 1\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVC (but not NuSVC) implement a keyword class_weight in the fit method.\n",
    "#Itâ€™s a dictionary of the form {class_label : value}, where value is a floating point number > 0\n",
    "#as it is unbalanced, balance the classes\n",
    "c = count_balancing(labels)\n",
    "weight = {i: psvm.nbPairs/float(c[i]) for i in c.keys()}\n",
    "\n",
    "#define the SVM\n",
    "psvm.clf = svm.LinearSVC(class_weight=weight)\n",
    "#psvm.clf = svm.SVC(probability=True, class_weight=weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 86.8259999752s\n"
     ]
    }
   ],
   "source": [
    "#train it\n",
    "start = time()\n",
    "psvm.clf.fit(trainingFeature,labels)\n",
    "print (\"Done in \" + str(time() - start) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for tdoc in test:\n",
    "    for sentence in tdoc.sentences:\n",
    "        if len(sentence.entities) >= 2:\n",
    "            for p in sentence.pairs:\n",
    "                s = p.textBetween\n",
    "                s = s.lower().split(' ')\n",
    "                f = get_features_from_text(s).reshape(1,-1)\n",
    "                \n",
    "                pred = classe_mapping[psvm.clf.predict(f)[0]]\n",
    "                true = p.getLabel()\n",
    "                \n",
    "                total += 1\n",
    "                \n",
    "                if pred == true:\n",
    "                    correct += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 5834\n",
      "total: 6923\n",
      "precision: 84.27%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precision = round(100*100*float(correct)/total)/100\n",
    "print(\"correct: \"+str(correct))\n",
    "print(\"total: \"+str(total))\n",
    "print(\"precision: \"+str(precision)+ \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
